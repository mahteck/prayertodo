# Phase I Implementation Plan â€“ SalaatFlow In-Memory Python Console App

**Project**: SalaatFlow â€“ Intelligent Prayer & Masjid Todo Assistant
**Phase**: I â€“ In-Memory Python Console Application
**Plan Version**: 1.0
**Date**: 2025-12-27
**Status**: Ready for Execution

---

## Plan Overview

This plan breaks down the implementation of Phase I into **8 ordered steps**, progressing from project setup through core features, integration, testing, and documentation. Each step defines clear goals, artifacts to be generated, and validation criteria.

### Implementation Method
**CRITICAL**: All production code will be **generated by Claude Code** based on the Phase I specification (`/specs/phase1-cli.md`). The human will NOT write any manual production code. Claude Code will:
1. Read the specification
2. Generate complete, working code for each step
3. Validate against acceptance criteria
4. Iterate based on test results

---

## Step 1: Project Setup & Foundation

### Goal
Establish the project structure, create foundational modules, and define constants and type definitions.

### Artifacts to Generate
1. **Directory Structure**:
   ```
   phase1/
   â”œâ”€â”€ main.py              # Entry point (placeholder)
   â”œâ”€â”€ models.py            # Task data model
   â”œâ”€â”€ storage.py           # In-memory storage manager
   â”œâ”€â”€ commands.py          # Command handlers (placeholder)
   â”œâ”€â”€ validators.py        # Input validation functions
   â”œâ”€â”€ display.py           # Output formatting
   â””â”€â”€ README.md            # Usage instructions (initial version)
   ```

2. **`models.py`**:
   - Task dataclass or TypedDict with all 10 fields
   - Category constants (FARZ, SUNNAH, NAFL, DEED)
   - Type aliases for clarity

3. **`validators.py`**:
   - `validate_title(title: str) -> tuple[bool, str]`
   - `validate_category(choice: str) -> tuple[bool, str]`
   - `validate_datetime(datetime_str: str) -> tuple[bool, Optional[datetime]]`
   - `validate_id(id_str: str) -> tuple[bool, Optional[int]]`
   - Field length constants (MAX_TITLE_LENGTH=200, etc.)

4. **`storage.py`**:
   - `TaskStorage` class with:
     - `tasks: List[dict]` attribute
     - `next_id: int` attribute
     - `add_task(task: dict) -> int`
     - `get_task(task_id: int) -> Optional[dict]`
     - `update_task(task_id: int, updates: dict) -> bool`
     - `delete_task(task_id: int) -> bool`
     - `list_tasks(filter: str = "all") -> List[dict]`

### Validation Criteria
- [ ] All files created in `phase1/` directory
- [ ] `models.py` defines Task structure with correct field types
- [ ] Category constants defined: "Farz", "Sunnah", "Nafl", "Deed"
- [ ] `validators.py` has all 4 validation functions with proper return types
- [ ] `storage.py` has TaskStorage class with 5 core methods
- [ ] No syntax errors when running: `python -m py_compile phase1/*.py`
- [ ] Type hints present on all function signatures

**Command to Validate**:
```bash
cd phase1
python -c "from models import *; from validators import *; from storage import TaskStorage; print('âœ“ Foundation modules loaded successfully')"
```

---

## Step 2: Display Formatting Module

### Goal
Implement output formatting functions for tables, messages, and the welcome banner.

### Artifacts to Generate
1. **`display.py`** with functions:
   - `show_welcome_banner() -> None`
   - `show_help() -> None`
   - `show_task_table(tasks: List[dict]) -> None`
   - `show_task_detail(task: dict) -> None`
   - `format_datetime(dt: Optional[datetime]) -> str`
   - `format_status(completed: bool) -> str` (returns "[âœ“]" or "[ ]")
   - Error message helpers

### Validation Criteria
- [ ] `show_welcome_banner()` displays exact banner from spec (section 4.1)
- [ ] `show_help()` displays exact help text from spec (section 3.2.1)
- [ ] `show_task_table()` formats tasks in columnar layout matching spec (section 3.2.3)
- [ ] `show_task_detail()` shows all task fields in vertical format (section 3.2.4)
- [ ] `format_datetime()` handles None values (displays "-")
- [ ] `format_status()` returns "[âœ“]" for completed, "[ ]" for pending

**Manual Test Script**:
```python
from display import *
from datetime import datetime

# Test banner
show_welcome_banner()

# Test help
show_help()

# Test table with sample data
sample_tasks = [
    {
        "id": 1,
        "title": "Attend Fajr at Masjid Al-Huda",
        "description": "Wake up early",
        "category": "Farz",
        "masjid_name": "Masjid Al-Huda",
        "area_name": "DHA Phase 5",
        "due_datetime": datetime(2025, 12, 28, 5, 30),
        "completed": False,
        "created_at": datetime.now(),
        "updated_at": datetime.now()
    }
]
show_task_table(sample_tasks)

# Test detail view
show_task_detail(sample_tasks[0])
```

---

## Step 3: Command Handlers â€“ Part 1 (Read Operations)

### Goal
Implement read-only commands: `help`, `list`, `view`.

### Artifacts to Generate
1. **`commands.py`** â€“ Initial implementation with:
   - `handle_help(storage: TaskStorage) -> None`
   - `handle_list(storage: TaskStorage, args: List[str]) -> None`
   - `handle_view(storage: TaskStorage, args: List[str]) -> None`

### Implementation Details
- **`handle_help`**: Call `display.show_help()`
- **`handle_list`**:
  - Parse optional filter argument (all/pending/completed)
  - Validate filter value
  - Call `storage.list_tasks(filter)`
  - Call `display.show_task_table(tasks)`
  - Show summary: "Total: X tasks (Y completed, Z pending)"
  - Handle empty list: "No tasks found."
- **`handle_view`**:
  - Validate ID argument exists and is numeric
  - Call `storage.get_task(id)`
  - Handle not found error
  - Call `display.show_task_detail(task)`

### Validation Criteria
- [ ] `help` command displays full help text
- [ ] `list` without args shows all tasks
- [ ] `list pending` filters to incomplete tasks only
- [ ] `list completed` filters to completed tasks only
- [ ] `list invalid_filter` shows error message
- [ ] `view <id>` shows detailed task information
- [ ] `view 999` (non-existent) shows error: "Error: Task with ID 999 not found."
- [ ] `view abc` shows error: "Error: Invalid task ID. Please enter a number."

**Test Script**:
```python
from storage import TaskStorage
from commands import handle_help, handle_list, handle_view

storage = TaskStorage()
# Add sample task manually
storage.add_task({...})

# Test commands
handle_help(storage)
handle_list(storage, [])
handle_list(storage, ["pending"])
handle_view(storage, ["1"])
handle_view(storage, ["999"])
```

---

## Step 4: Command Handlers â€“ Part 2 (Write Operations - Add)

### Goal
Implement the `add` command with full interactive prompts and validation.

### Artifacts to Generate
1. **Update `commands.py`** with:
   - `handle_add(storage: TaskStorage) -> None`
   - Helper: `prompt_for_task_data() -> dict`
   - Helper: `prompt_category() -> str`
   - Helper: `prompt_datetime() -> Optional[datetime]`

### Implementation Details
- **`prompt_for_task_data()`**:
  - Prompt for title (required, validate with `validators.validate_title()`)
  - Re-prompt on validation failure
  - Prompt for description (optional, press Enter to skip)
  - Call `prompt_category()` for category selection
  - Prompt for masjid_name (optional)
  - Prompt for area_name (optional)
  - Call `prompt_datetime()` for due_datetime
  - Return dict with all user-provided values

- **`prompt_category()`**:
  - Display numbered menu (1. Farz, 2. Sunnah, 3. Nafl, 4. Deed)
  - Read input, validate with `validators.validate_category()`
  - Re-prompt on invalid choice
  - Return category string

- **`prompt_datetime()`**:
  - Prompt for "YYYY-MM-DD HH:MM" format
  - If empty, return None
  - Validate with `validators.validate_datetime()`
  - Re-prompt on invalid format
  - Return datetime object or None

- **`handle_add()`**:
  - Call `prompt_for_task_data()`
  - Auto-generate: id (from storage), created_at, updated_at, completed=False
  - Call `storage.add_task(task)`
  - Display: "Task added successfully! (ID: X)"

### Validation Criteria
- [ ] Prompts match spec exactly (section 3.2.2)
- [ ] Required field (title) re-prompts when empty
- [ ] Category menu shows 4 options, validates 1-4
- [ ] Invalid category choice re-prompts
- [ ] Datetime accepts "YYYY-MM-DD HH:MM" format
- [ ] Invalid datetime re-prompts or allows skip
- [ ] Empty optional fields allowed (press Enter)
- [ ] Task stored with auto-generated id, timestamps, completed=False
- [ ] Success message shows assigned ID

**Interactive Test** (manual execution):
```bash
python main.py
> add
# Follow prompts, enter valid data
# Verify "Task added successfully! (ID: 1)"
> list
# Verify new task appears
```

---

## Step 5: Command Handlers â€“ Part 3 (Write Operations - Update, Delete, Complete)

### Goal
Implement `update`, `delete`, `complete`, and `uncomplete` commands.

### Artifacts to Generate
1. **Update `commands.py`** with:
   - `handle_update(storage: TaskStorage, args: List[str]) -> None`
   - `handle_delete(storage: TaskStorage, args: List[str]) -> None`
   - `handle_complete(storage: TaskStorage, args: List[str]) -> None`
   - `handle_uncomplete(storage: TaskStorage, args: List[str]) -> None`
   - Helper: `prompt_for_update_data(current_task: dict) -> dict`
   - Helper: `confirm_deletion(task: dict) -> bool`

### Implementation Details
- **`handle_update()`**:
  - Validate ID argument
  - Fetch task from storage
  - Handle not found
  - Call `prompt_for_update_data(task)` for new values
  - Update `updated_at` timestamp
  - Call `storage.update_task(id, updates)`
  - Display: "Task updated successfully!"

- **`prompt_for_update_data()`**:
  - For each field, show current value
  - Prompt "New X (press Enter to keep current):"
  - If empty, keep current value
  - If not empty, validate and use new value
  - Return dict of updates

- **`handle_delete()`**:
  - Validate ID argument
  - Fetch task from storage
  - Call `confirm_deletion(task)`
  - If confirmed, call `storage.delete_task(id)`
  - Display: "Task deleted successfully!" or "Deletion cancelled."

- **`confirm_deletion()`**:
  - Display task ID and title
  - Prompt "Confirm deletion? (y/n):"
  - Return True if 'y', False otherwise

- **`handle_complete()` / `handle_uncomplete()`**:
  - Validate ID argument
  - Fetch task from storage
  - Check if already in target state â†’ show message
  - Update `completed` and `updated_at`
  - Call `storage.update_task()`
  - Display: "Task ID X marked as completed/incomplete!"

### Validation Criteria
- [ ] `update 1` shows current values and allows keeping them
- [ ] `update 1` accepts new values and validates them
- [ ] `update 999` shows error: "Task with ID 999 not found."
- [ ] `delete 1` prompts for confirmation showing task details
- [ ] Entering 'n' cancels deletion
- [ ] Entering 'y' deletes task
- [ ] `complete 1` marks task as completed
- [ ] `complete 1` (already completed) shows: "Task ID 1 is already completed."
- [ ] `uncomplete 1` marks task as incomplete
- [ ] All commands update `updated_at` timestamp

**Test Session** (from spec section 5.3):
```
> view 3
> update 3
# Follow prompts
> view 3
# Verify updated fields and timestamp
```

---

## Step 6: Main REPL Loop & Command Dispatcher

### Goal
Implement the main application loop with command parsing and error handling.

### Artifacts to Generate
1. **`main.py`** â€“ Complete implementation:
   - `parse_command(input: str) -> tuple[str, List[str]]`
   - `dispatch_command(cmd: str, args: List[str], storage: TaskStorage) -> bool`
   - `main() -> None`

### Implementation Details
- **`parse_command()`**:
  - Split input on whitespace
  - First token is command, rest are args
  - Return (command, args)
  - Handle empty input gracefully

- **`dispatch_command()`**:
  - Match command to handler:
    - "help" â†’ `commands.handle_help()`
    - "add" â†’ `commands.handle_add()`
    - "list" â†’ `commands.handle_list(args)`
    - "view" â†’ `commands.handle_view(args)`
    - "update" â†’ `commands.handle_update(args)`
    - "delete" â†’ `commands.handle_delete(args)`
    - "complete" â†’ `commands.handle_complete(args)`
    - "uncomplete" â†’ `commands.handle_uncomplete(args)`
    - "exit" â†’ return False (signal to exit)
    - unknown â†’ display error
  - Return True to continue loop, False to exit

- **`main()`**:
  - Initialize TaskStorage
  - Call `display.show_welcome_banner()`
  - Call `display.show_help()`
  - Loop:
    - Print "salaatflow> " prompt
    - Read user input
    - Call `parse_command()`
    - Call `dispatch_command()`
    - Break loop if dispatch returns False
  - Display farewell message (spec section 3.2.9)

### Validation Criteria
- [ ] Application starts with welcome banner and help text
- [ ] Prompt displays as "salaatflow> "
- [ ] Valid commands execute correctly
- [ ] Unknown commands show: "Error: Unknown command '{cmd}'. Type 'help' for available commands."
- [ ] Commands missing required args show: "Error: Command '{cmd}' requires argument(s). Usage: {usage}"
- [ ] `exit` command displays: "JazakAllah Khair for using SalaatFlow! May your deeds be accepted."
- [ ] Application terminates gracefully after exit
- [ ] Ctrl+C handled gracefully (optional but recommended)

**Full Application Test**:
```bash
cd phase1
python main.py
# Test all commands from spec section 5
```

---

## Step 7: Comprehensive Testing Against Acceptance Criteria

### Goal
Execute all 5 test sessions from the specification and verify behavior matches expected outcomes.

### Test Execution Plan

#### Test Session 1: Basic CRUD Operations (Spec Section 5.1)
- Add 3 tasks with different categories and attributes
- List all tasks
- Complete task ID 1
- List again (verify completion status updated)
- Delete task ID 2 with confirmation
- List again (verify deletion)

**Expected Result**: All operations succeed, output matches spec exactly

#### Test Session 2: Filtering Tasks (Spec Section 5.2)
- Using state from Session 1
- Run `list pending`
- Run `list completed`
- Run `list all`
- Verify each filter shows only matching tasks
- Verify summary counts are correct

**Expected Result**: Filters work correctly, no incorrect tasks shown

#### Test Session 3: Update Task (Spec Section 5.3)
- View task ID 3 in detail
- Update task ID 3 (change description, masjid, area, due_datetime)
- View task ID 3 again
- Verify all updated fields changed
- Verify `updated_at` timestamp changed
- Verify `created_at` timestamp unchanged

**Expected Result**: Updates applied correctly, timestamps managed properly

#### Test Session 4: Error Handling (Spec Section 5.4)
- Try invalid command
- Try `delete` without ID argument
- Try `delete 999` (non-existent ID)
- Try `complete abc` (invalid ID format)
- Try `view 999` (non-existent ID)
- Try `list invalid_filter`

**Expected Result**: All errors handled gracefully with appropriate messages, application continues running

#### Test Session 5: Complete Workflow (Spec Section 5.5)
- Add 2 more tasks (IDs 4 and 5)
- List pending tasks
- Complete task ID 4
- Uncomplete task ID 1
- List all tasks
- Exit application

**Expected Result**: Realistic daily usage works seamlessly

### Artifacts to Generate
1. **`phase1/TESTING.md`** â€“ Test execution log:
   - Document each test session
   - Record actual output
   - Note any discrepancies
   - Mark each session PASS/FAIL

### Validation Criteria
- [ ] All 5 test sessions execute without crashes
- [ ] All test sessions produce expected output
- [ ] All acceptance criteria marked âœ… in spec
- [ ] No unexpected behavior or bugs discovered
- [ ] If bugs found, they are documented and fixed before proceeding

---

## Step 8: Documentation & Final Polish

### Goal
Complete user-facing documentation and perform final code review.

### Artifacts to Generate
1. **`phase1/README.md`** â€“ Complete usage guide:
   - Project description
   - Installation instructions (Python version requirement)
   - How to run: `python main.py`
   - Command reference (summary of all 9 commands)
   - Example usage session
   - Domain explanation (Islamic spiritual tasks)
   - Phase I scope and limitations
   - Link to full spec

2. **Code Review Checklist** (documented in implementation):
   - [ ] All functions have type hints
   - [ ] All public functions have docstrings
   - [ ] No hardcoded values (use constants)
   - [ ] Consistent error message formatting
   - [ ] No code duplication (DRY principle)
   - [ ] Category values exactly match spec ("Farz", "Sunnah", "Nafl", "Deed")
   - [ ] Datetime format validated as "YYYY-MM-DD HH:MM"
   - [ ] Field length limits enforced (title â‰¤200, etc.)

3. **Final Validation**:
   - Run Python linter (optional): `pylint phase1/*.py`
   - Type check (optional): `mypy phase1/`
   - Ensure Python 3.11+ compatibility

### Validation Criteria
- [ ] README.md is clear and comprehensive
- [ ] Installation steps tested on fresh environment
- [ ] Example session in README matches actual behavior
- [ ] All code quality standards from spec section 6.4 met
- [ ] No TODOs or placeholder comments in code
- [ ] All files have proper headers/docstrings
- [ ] Project ready for demo and handoff to Phase II

**Final Smoke Test**:
```bash
# Fresh terminal
cd phase1
python main.py
# Run quick test: add task, list, complete, exit
# Verify output matches expectations
```

---

## Implementation Workflow

### For Claude Code (AI Implementation Agent)

Each step will be implemented as follows:

1. **Read** the Phase I specification (`/specs/phase1-cli.md`)
2. **Read** this implementation plan
3. **Generate** code for the current step's artifacts
4. **Validate** using the step's validation criteria
5. **Test** manually or via test scripts
6. **Document** any deviations or issues
7. **Proceed** to next step only when current step passes validation

### For Human (Project Owner)

The human will:
1. **Invoke** `/sp.tasks` to break this plan into executable tasks
2. **Invoke** `/sp.implement` to have Claude Code generate code
3. **Review** generated code for alignment with spec
4. **Execute** manual tests where specified
5. **Provide feedback** if behavior doesn't match spec
6. **Approve** each step before proceeding to next

### Critical Reminders

ðŸš¨ **NO MANUAL CODING**: The human must not write production code. All code generated by Claude Code.

ðŸš¨ **SPEC IS SOURCE OF TRUTH**: If generated code doesn't match spec, regenerate code (don't patch spec).

ðŸš¨ **VALIDATE EACH STEP**: Don't proceed to next step until current step's validation passes.

ðŸš¨ **TEST BEFORE INTEGRATION**: Test each module/function in isolation before integrating.

---

## Success Criteria for Phase I Completion

Phase I is considered **complete** when:

- âœ… All 8 steps executed and validated
- âœ… All 5 acceptance test sessions pass (spec section 5)
- âœ… README.md complete and accurate
- âœ… No known bugs or crashes
- âœ… Code follows all quality standards (spec section 6.4)
- âœ… Application demonstrates all required commands working correctly
- âœ… Output matches spec examples exactly (formatting, messages, etc.)
- âœ… Project ready for demo and evolution to Phase II

---

## Phase I to Phase II Evolution Path

Upon completion of Phase I, the following migrations will occur in Phase II:

| Phase I Component | Phase II Evolution |
|-------------------|-------------------|
| `storage.py` in-memory list | Neon PostgreSQL with SQLModel ORM |
| `models.py` dict/dataclass | SQLModel database schema |
| `commands.py` CLI handlers | FastAPI REST endpoints |
| `display.py` console output | Next.js React components |
| Direct function calls | HTTP API calls (fetch/axios) |
| Manual testing | Automated API tests + E2E tests |

**DO NOT implement** database or web features in Phase I. Keep it simple.

---

## Estimated Effort (For Planning Only)

| Step | Description | Complexity | Key Risk |
|------|-------------|------------|----------|
| 1 | Project Setup | Low | None |
| 2 | Display Module | Low | Table formatting alignment |
| 3 | Read Commands | Medium | Edge cases in filtering |
| 4 | Add Command | Medium | Input validation loops |
| 5 | Write Commands | High | Update prompts complexity |
| 6 | Main REPL | Medium | Error handling coverage |
| 7 | Testing | Medium | Discovering edge cases |
| 8 | Documentation | Low | Completeness |

**Note**: No time estimates provided per project constitution guidelines. Focus is on completeness, not speed.

---

## References

- **Specification**: `/specs/phase1-cli.md`
- **Global Constitution**: `/specs/constitution.md` (to be created)
- **Next Steps**: `/sp.tasks` â†’ `/sp.implement`

---

**Plan Status**: âœ… Ready for Task Breakdown
**Next Command**: `/sp.tasks` to generate task list from this plan
